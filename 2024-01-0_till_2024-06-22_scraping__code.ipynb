{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63623f6",
   "metadata": {},
   "source": [
    "#  Gathering information about publications  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " This notebook alowes us to visit site [arxiv.org](https://arxiv.org) and scrape information about different publications \n",
    "in physics. In particular we are interested in the following topics: \n",
    "* Black Holes and General Relativity(GR)\n",
    "* Tensor Networks\n",
    "* Holography (aka AdS/CFT)\n",
    "* Quantum Computers ans Quantum Infomation\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07369a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26dcf21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdS/CFT\n",
      "BTZ black hole\n",
      "BTZ black holes\n",
      "MERA\n",
      "RT formula\n",
      "RT formula\n",
      "Renyi entropy\n",
      "bit thread\n",
      "black holes\n",
      "bulk geometry\n",
      "cMERA\n",
      "continuous tensor network\n",
      "einstein equations\n",
      "emergent space-time geometry\n",
      "entanglement of assistance\n",
      "entanglement of purification\n",
      "entanglement renormalization\n",
      "geodesics\n",
      "geometry of entangled states\n",
      "hawking radiation\n",
      "holographic code\n",
      "holographic duality\n",
      "holographic entanglement\n",
      "holographic shadow\n",
      "holography\n",
      "hyperbolic lattices\n",
      "large central charge\n",
      "matrix product state\n",
      "quantum bit threads\n",
      "quantum chaos\n",
      "quantum circuit\n",
      "quantum computer\n",
      "quantum error-correcting code\n",
      "quantum information theory\n",
      "quantum machine learning\n",
      "random quantum circuits\n",
      "stabilizer state\n",
      "tensor network\n",
      "tensor networks\n",
      "tensor networks in machine learning\n",
      "traversable wormhole\n",
      "traversable wormholes\n"
     ]
    }
   ],
   "source": [
    "                            ##  We adjust list of key words for articles ##\n",
    "    \n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        # Only append non-empty strings\n",
    "        if paragraph.text.strip():\n",
    "            text.append(paragraph.text.strip())\n",
    "    return text\n",
    "\n",
    "key_words_file_path = 'articles_to_analyse/words_for_search.docx'\n",
    "key_words_list = read_docx(key_words_file_path)\n",
    "\n",
    "# if  we want to add some words but we don't want to modify docx file right now:\n",
    "words_to_add = ['traversable wormhole',\n",
    "                'RT formula', 'random quantum circuits',\n",
    "                'quantum circuit', \n",
    "                'black holes',\n",
    "                'matrix product state',\n",
    "                'large central charge',\n",
    "                'quantum chaos'\n",
    "                ]\n",
    "key_words_list.extend(words_to_add)\n",
    "for word in sorted(key_words_list):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ee3eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall number of articles released from 2024-01-01 till 2024-06-22 is: 51739\n"
     ]
    }
   ],
   "source": [
    "def total_number_of_articles(to_date, from_date):\n",
    "    \n",
    "\n",
    "    url = 'https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=&terms-0-field=title&classification-physics=y&classification-physics_archives=all&classification-include_cross_list=include&date-year=&date-filter_by=date_range&date-from_date='+ from_date +'&date-to_date='+ to_date +'&date-date_type=submitted_date&abstracts=show&size=200&order=-announced_date_first&start=0' \n",
    "\n",
    "    # Send an HTTP GET request to the webpage\n",
    "    response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "            # Get the HTML content of the webpage\n",
    "        arxiv_page_content = response.text\n",
    "    else:\n",
    "        print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "    # Regular expression pattern to extract the desired number\n",
    "    pattern = r'Showing \\d+&ndash;\\d+ of (\\d{1,3}(?:,\\d{3})*) results'\n",
    "\n",
    "    # Search for the pattern in the content\n",
    "    match = re.search(pattern, arxiv_page_content)\n",
    "\n",
    "    # Extract the number if match found\n",
    "    if match:\n",
    "        result = int(match.group(1).replace(',', ''))\n",
    "        return result \n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "to_date = '2024-06-22'    # 'YYYY-MM-DD'\n",
    "from_date = '2024-01-01'  # 'YYYY-MM-DD'\n",
    "    \n",
    "print(f\"The overall number of articles released from {from_date} till {to_date} is: {total_number_of_articles(to_date, from_date)}\")    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6139ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetching_webpage(from_date, to_date, starting_num):\n",
    "    \n",
    "    \n",
    "        ## This function returns string that contains Page source code for  advanced search for physics articles for 200 articles starting from starting_num\n",
    "        url = 'https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=&terms-0-field=title&classification-physics=y&classification-physics_archives=all&classification-include_cross_list=include&date-year=&date-filter_by=date_range&date-from_date='+ from_date +'&date-to_date='+ to_date +'&date-date_type=submitted_date&abstracts=show&size=200&order=-announced_date_first&start='+ str(starting_num) \n",
    "\n",
    "        # Send an HTTP GET request to the webpage\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Get the HTML content of the webpage\n",
    "            arxiv_page_content = response.text\n",
    "        else:\n",
    "            print(f\"Failed to fetch webpage. Status code: {response.status_code}\")    \n",
    "            \n",
    "        return arxiv_page_content     \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be304247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_date_on_a_webpage(arxiv_page_content, table_arxiv):\n",
    "    \n",
    "    \n",
    "        yy = table_arxiv[-1][0][22:24]\n",
    "        mm = table_arxiv[-1][0][24:26]\n",
    "\n",
    "        # Define the pattern\n",
    "        pattern = r'<span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span>.*?<span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span>'\n",
    "\n",
    "        # Find all matches of the pattern\n",
    "        matches = re.finditer(pattern, arxiv_page_content, re.DOTALL)\n",
    "\n",
    "        # Get the last match\n",
    "        last_match = None\n",
    "        for match in matches:\n",
    "            last_match = match\n",
    "        answer = last_match.group()\n",
    "\n",
    "\n",
    "        # Define the pattern to extract the date\n",
    "        pattern = r'<span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span>\\s*(.*?)\\s*;'\n",
    "\n",
    "        # Search for the pattern in the text\n",
    "        match = re.search(pattern, answer)\n",
    "\n",
    "        # If a match is found, extract the date\n",
    "        if match:\n",
    "           date_text = match.group(1)\n",
    "           # Extract the day part from the date\n",
    "           date_match = re.search(r'\\d+', date_text)\n",
    "           if date_match:\n",
    "              dd = date_match.group()    \n",
    "    \n",
    "        new_to_date = '20'+ str(yy) + '-' + str(mm) + '-' + str(dd)\n",
    "        \n",
    "        return new_to_date\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75842af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "  returns: arxiv_table =  [['link_to_article',\n",
    "                            'name_of_the_article', \n",
    "                            'author1, author2,..', \n",
    "                            'Abstract_full_version',\n",
    "                            {key_words_1: n_1, key_words_2: n_2,...}],\n",
    "                            ...]\n",
    "\n",
    "\n",
    "  example of an article from arxiv_table: \n",
    "            arxiv_table[i] = ['https://arxiv.org/pdf/2403.07275', \n",
    "             \n",
    "                              'Coarse-graining black holes out of equilibrium with boundary observables on time slice',\n",
    "                              \n",
    "                              'Daichi Takeda',\n",
    "                              \n",
    "                              'In black hole thermodynamics, defining coarse-grained entropy have been explored.\n",
    "                               Guided by the AdS/CFT, we introduce a new definition of coarse-grained entropy.The entropy is shown \n",
    "                               to satisfy a generalized first law and, through holography, the second law as well. \n",
    "                               By applying this thermodynamics to several Vaidya models in AdS and flat spacetime, we discover a \n",
    "                               connection between the second law and the null energy condition.△ Less', \n",
    "                               \n",
    "                               {'AdS/CFT': 1, 'holography': 1}]\n",
    "     \n",
    " \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_table_arxiv(arxiv_page_content, key_words_list):\n",
    "    table_arxiv = []\n",
    "    soup = BeautifulSoup(arxiv_page_content, 'html.parser')\n",
    "\n",
    "    # Define the regex pattern to match the IDs\n",
    "    id_pattern = re.compile(r'(\\d{4}\\.\\d{5}(v\\d+)?)')\n",
    "    \n",
    "    # Find all occurrences of the title, author, and abstract patterns\n",
    "    titles = re.findall(r'<p class=\"title is-5 mathjax\">\\s*(.*?)\\s*</p>', arxiv_page_content)\n",
    "    author_blocks = re.findall(r'<p class=\"authors\">(.*?)</p>', arxiv_page_content, re.DOTALL)\n",
    "    abstract_full_elements = soup.find_all('span', class_='abstract-full')\n",
    "\n",
    "    # Initialize authors list and abstracts list\n",
    "    authors_list = []\n",
    "    abstracts = []\n",
    "\n",
    "    # Extract authors using BeautifulSoup instead of regex\n",
    "    for block in soup.find_all('p', class_='authors'):\n",
    "        authors = [a.text for a in block.find_all('a')]\n",
    "        formatted_authors = \", \".join(authors)\n",
    "        authors_list.append(formatted_authors)\n",
    "    \n",
    "    # Extract abstracts\n",
    "    for element in abstract_full_elements:\n",
    "        abstracts.append(element.get_text(strip=True))\n",
    "\n",
    "    # Extract IDs\n",
    "    extracted_ids = []\n",
    "    for span in soup.find_all('span', {'class': 'abstract-short'}):\n",
    "        if span.has_attr('id'):\n",
    "            match = id_pattern.search(span['id'])\n",
    "            if match:\n",
    "                extracted_ids.append(match.group(1))\n",
    "    \n",
    "    # Iterate over the extracted elements\n",
    "    for i in range(max(len(extracted_ids), len(titles), len(authors_list), len(abstracts))):\n",
    "        sublist = []\n",
    "        sublist.append(extracted_ids[i] if i < len(extracted_ids) else np.nan)\n",
    "        sublist.append(titles[i] if i < len(titles) else np.nan)\n",
    "        sublist.append(authors_list[i] if i < len(authors_list) else np.nan)\n",
    "        sublist.append(abstracts[i] if i < len(abstracts) else np.nan)\n",
    "\n",
    "        # If the abstract is a string, search for keywords\n",
    "        if isinstance(sublist[3], str):\n",
    "            word_counts = {}\n",
    "            for word in key_words_list:\n",
    "                pattern = re.compile(r'\\b' + re.escape(word) + r'\\b', re.IGNORECASE)\n",
    "                matches = pattern.findall(sublist[3])\n",
    "                count = len(matches)\n",
    "                if count != 0:\n",
    "                    word_counts[word] = count\n",
    "\n",
    "            sorted_word_counts = dict(sorted(word_counts.items(), key=lambda item: item[0]))\n",
    "            if len(sorted_word_counts) != 0:\n",
    "                sublist.append(sorted_word_counts)\n",
    "                table_arxiv.append(sublist)  # Append only if sorted_word_counts is non-zero\n",
    "                \n",
    "                \n",
    "                \n",
    "    for article in table_arxiv:     \n",
    "        article[0] = 'https://arxiv.org/pdf/' + str(article[0]) # Convert 2403.07972v1 to https://arxiv.org/pdf/2403.07972v1\n",
    "        article[3] = article[3][:-6]   # Delete \"△ Less\" from the end of every Abstract# \n",
    "        \n",
    "    return table_arxiv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97743b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This fucntion puts together the everything that needs to be done in order to get info about the articles\n",
    "### Note that advanced search at arxiv.org shows no more than 200 publications per page\n",
    "### Total number of articles that can be scrolled this way is no more than 10000\n",
    "### If we want to go through more than 10000 publications, which is usually the case we need to take these issues into account\n",
    "\n",
    "\n",
    "\n",
    "def THE_FUNCTION(from_date, to_date, resulting_table=None):\n",
    "    if resulting_table is None:\n",
    "        resulting_table = []\n",
    "    \n",
    "    total_num_of_articles = total_number_of_articles(to_date, from_date)\n",
    "    \n",
    "    if total_num_of_articles <= 10000:\n",
    "        for starting_num in range(0, total_num_of_articles, 200):\n",
    "            print(starting_num)\n",
    "            arxiv_page_content = fetching_webpage(from_date, to_date, starting_num)\n",
    "            resulting_table.extend(create_table_arxiv(arxiv_page_content, key_words_list))\n",
    "            print(f\"number of interesting articles: {len(resulting_table)}\")\n",
    "    else:\n",
    "        for starting_num in range(0, 10000, 200):\n",
    "            print(starting_num)\n",
    "            arxiv_page_content = fetching_webpage(from_date, to_date, starting_num)\n",
    "            resulting_table.extend(create_table_arxiv(arxiv_page_content, key_words_list))\n",
    "            print(f\"number of interesting articles: {len(resulting_table)}\")\n",
    "\n",
    "            if starting_num == 9800:\n",
    "                new_to_date = find_last_date_on_a_webpage(arxiv_page_content, resulting_table)\n",
    "                return THE_FUNCTION(from_date, new_to_date, resulting_table)  # Pass the current table for updating\n",
    "    \n",
    "    return resulting_table\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "946a680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "number of interesting articles: 4\n",
      "200\n",
      "number of interesting articles: 5\n",
      "400\n",
      "number of interesting articles: 23\n",
      "600\n",
      "number of interesting articles: 33\n",
      "800\n",
      "number of interesting articles: 47\n",
      "1000\n",
      "number of interesting articles: 61\n",
      "1200\n",
      "number of interesting articles: 80\n",
      "1400\n",
      "number of interesting articles: 93\n",
      "1600\n",
      "number of interesting articles: 104\n",
      "1800\n",
      "number of interesting articles: 119\n",
      "2000\n",
      "number of interesting articles: 133\n",
      "2200\n",
      "number of interesting articles: 146\n",
      "2400\n",
      "number of interesting articles: 157\n",
      "2600\n",
      "number of interesting articles: 174\n",
      "2800\n",
      "number of interesting articles: 186\n",
      "3000\n",
      "number of interesting articles: 199\n",
      "3200\n",
      "number of interesting articles: 209\n",
      "3400\n",
      "number of interesting articles: 220\n",
      "3600\n",
      "number of interesting articles: 234\n",
      "3800\n",
      "number of interesting articles: 249\n",
      "4000\n",
      "number of interesting articles: 268\n",
      "4200\n",
      "number of interesting articles: 276\n",
      "4400\n",
      "number of interesting articles: 289\n",
      "4600\n",
      "number of interesting articles: 305\n",
      "4800\n",
      "number of interesting articles: 311\n",
      "5000\n",
      "number of interesting articles: 317\n",
      "5200\n",
      "number of interesting articles: 334\n",
      "5400\n",
      "number of interesting articles: 345\n",
      "5600\n",
      "number of interesting articles: 356\n",
      "5800\n",
      "number of interesting articles: 370\n",
      "6000\n",
      "number of interesting articles: 387\n",
      "6200\n",
      "number of interesting articles: 394\n",
      "6400\n",
      "number of interesting articles: 406\n",
      "6600\n",
      "number of interesting articles: 415\n",
      "6800\n",
      "number of interesting articles: 424\n",
      "7000\n",
      "number of interesting articles: 436\n",
      "7200\n",
      "number of interesting articles: 447\n",
      "7400\n",
      "number of interesting articles: 461\n",
      "7600\n",
      "number of interesting articles: 479\n",
      "7800\n",
      "number of interesting articles: 491\n",
      "8000\n",
      "number of interesting articles: 501\n",
      "8200\n",
      "number of interesting articles: 512\n",
      "8400\n",
      "number of interesting articles: 527\n",
      "8600\n",
      "number of interesting articles: 543\n",
      "8800\n",
      "number of interesting articles: 554\n",
      "9000\n",
      "number of interesting articles: 570\n",
      "9200\n",
      "number of interesting articles: 582\n",
      "9400\n",
      "number of interesting articles: 591\n",
      "9600\n",
      "number of interesting articles: 603\n",
      "9800\n",
      "number of interesting articles: 616\n",
      "0\n",
      "number of interesting articles: 626\n",
      "200\n",
      "number of interesting articles: 638\n",
      "400\n",
      "number of interesting articles: 653\n",
      "600\n",
      "number of interesting articles: 665\n",
      "800\n",
      "number of interesting articles: 674\n",
      "1000\n",
      "number of interesting articles: 690\n",
      "1200\n",
      "number of interesting articles: 701\n",
      "1400\n",
      "number of interesting articles: 708\n",
      "1600\n",
      "number of interesting articles: 722\n",
      "1800\n",
      "number of interesting articles: 737\n",
      "2000\n",
      "number of interesting articles: 756\n",
      "2200\n",
      "number of interesting articles: 766\n",
      "2400\n",
      "number of interesting articles: 774\n",
      "2600\n",
      "number of interesting articles: 783\n",
      "2800\n",
      "number of interesting articles: 789\n",
      "3000\n",
      "number of interesting articles: 798\n",
      "3200\n",
      "number of interesting articles: 813\n",
      "3400\n",
      "number of interesting articles: 828\n",
      "3600\n",
      "number of interesting articles: 840\n",
      "3800\n",
      "number of interesting articles: 851\n",
      "4000\n",
      "number of interesting articles: 865\n",
      "4200\n",
      "number of interesting articles: 879\n",
      "4400\n",
      "number of interesting articles: 895\n",
      "4600\n",
      "number of interesting articles: 910\n",
      "4800\n",
      "number of interesting articles: 921\n",
      "5000\n",
      "number of interesting articles: 940\n",
      "5200\n",
      "number of interesting articles: 955\n",
      "5400\n",
      "number of interesting articles: 970\n",
      "5600\n",
      "number of interesting articles: 981\n",
      "5800\n",
      "number of interesting articles: 988\n",
      "6000\n",
      "number of interesting articles: 994\n",
      "6200\n",
      "number of interesting articles: 1010\n",
      "6400\n",
      "number of interesting articles: 1021\n",
      "6600\n",
      "number of interesting articles: 1037\n",
      "6800\n",
      "number of interesting articles: 1057\n",
      "7000\n",
      "number of interesting articles: 1068\n",
      "7200\n",
      "number of interesting articles: 1081\n",
      "7400\n",
      "number of interesting articles: 1098\n",
      "7600\n",
      "number of interesting articles: 1105\n",
      "7800\n",
      "number of interesting articles: 1122\n",
      "8000\n",
      "number of interesting articles: 1132\n",
      "8200\n",
      "number of interesting articles: 1144\n",
      "8400\n",
      "number of interesting articles: 1153\n",
      "8600\n",
      "number of interesting articles: 1167\n",
      "8800\n",
      "number of interesting articles: 1180\n",
      "9000\n",
      "number of interesting articles: 1194\n",
      "9200\n",
      "number of interesting articles: 1214\n",
      "9400\n",
      "number of interesting articles: 1224\n",
      "9600\n",
      "number of interesting articles: 1234\n",
      "9800\n",
      "number of interesting articles: 1242\n",
      "0\n",
      "number of interesting articles: 1252\n",
      "200\n",
      "number of interesting articles: 1270\n",
      "400\n",
      "number of interesting articles: 1281\n",
      "600\n",
      "number of interesting articles: 1301\n",
      "800\n",
      "number of interesting articles: 1312\n",
      "1000\n",
      "number of interesting articles: 1330\n",
      "1200\n",
      "number of interesting articles: 1345\n",
      "1400\n",
      "number of interesting articles: 1358\n",
      "1600\n",
      "number of interesting articles: 1370\n",
      "1800\n",
      "number of interesting articles: 1374\n",
      "2000\n",
      "number of interesting articles: 1381\n",
      "2200\n",
      "number of interesting articles: 1396\n",
      "2400\n",
      "number of interesting articles: 1407\n",
      "2600\n",
      "number of interesting articles: 1424\n",
      "2800\n",
      "number of interesting articles: 1446\n",
      "3000\n",
      "number of interesting articles: 1455\n",
      "3200\n",
      "number of interesting articles: 1466\n",
      "3400\n",
      "number of interesting articles: 1481\n",
      "3600\n",
      "number of interesting articles: 1490\n",
      "3800\n",
      "number of interesting articles: 1504\n",
      "4000\n",
      "number of interesting articles: 1516\n",
      "4200\n",
      "number of interesting articles: 1527\n",
      "4400\n",
      "number of interesting articles: 1540\n",
      "4600\n",
      "number of interesting articles: 1550\n",
      "4800\n",
      "number of interesting articles: 1563\n",
      "5000\n",
      "number of interesting articles: 1584\n",
      "5200\n",
      "number of interesting articles: 1598\n",
      "5400\n",
      "number of interesting articles: 1606\n",
      "5600\n",
      "number of interesting articles: 1612\n",
      "5800\n",
      "number of interesting articles: 1621\n",
      "6000\n",
      "number of interesting articles: 1629\n",
      "6200\n",
      "number of interesting articles: 1638\n",
      "6400\n",
      "number of interesting articles: 1649\n",
      "6600\n",
      "number of interesting articles: 1666\n",
      "6800\n",
      "number of interesting articles: 1682\n",
      "7000\n",
      "number of interesting articles: 1689\n",
      "7200\n",
      "number of interesting articles: 1696\n",
      "7400\n",
      "number of interesting articles: 1710\n",
      "7600\n",
      "number of interesting articles: 1719\n",
      "7800\n",
      "number of interesting articles: 1734\n",
      "8000\n",
      "number of interesting articles: 1741\n",
      "8200\n",
      "number of interesting articles: 1756\n",
      "8400\n",
      "number of interesting articles: 1765\n",
      "8600\n",
      "number of interesting articles: 1775\n",
      "8800\n",
      "number of interesting articles: 1785\n",
      "9000\n",
      "number of interesting articles: 1794\n",
      "9200\n",
      "number of interesting articles: 1807\n",
      "9400\n",
      "number of interesting articles: 1815\n",
      "9600\n",
      "number of interesting articles: 1830\n",
      "9800\n",
      "number of interesting articles: 1836\n",
      "0\n",
      "number of interesting articles: 1846\n",
      "200\n",
      "number of interesting articles: 1854\n",
      "400\n",
      "number of interesting articles: 1867\n",
      "600\n",
      "number of interesting articles: 1873\n",
      "800\n",
      "number of interesting articles: 1890\n",
      "1000\n",
      "number of interesting articles: 1898\n",
      "1200\n",
      "number of interesting articles: 1906\n",
      "1400\n",
      "number of interesting articles: 1919\n",
      "1600\n",
      "number of interesting articles: 1925\n",
      "1800\n",
      "number of interesting articles: 1933\n",
      "2000\n",
      "number of interesting articles: 1942\n",
      "2200\n",
      "number of interesting articles: 1950\n",
      "2400\n",
      "number of interesting articles: 1960\n",
      "2600\n",
      "number of interesting articles: 1966\n",
      "2800\n",
      "number of interesting articles: 1974\n",
      "3000\n",
      "number of interesting articles: 1984\n",
      "3200\n",
      "number of interesting articles: 1991\n",
      "3400\n",
      "number of interesting articles: 2000\n",
      "3600\n",
      "number of interesting articles: 2012\n",
      "3800\n",
      "number of interesting articles: 2022\n",
      "4000\n",
      "number of interesting articles: 2030\n",
      "4200\n",
      "number of interesting articles: 2038\n",
      "4400\n",
      "number of interesting articles: 2049\n",
      "4600\n",
      "number of interesting articles: 2060\n",
      "4800\n",
      "number of interesting articles: 2069\n",
      "5000\n",
      "number of interesting articles: 2077\n",
      "5200\n",
      "number of interesting articles: 2085\n",
      "5400\n",
      "number of interesting articles: 2090\n",
      "5600\n",
      "number of interesting articles: 2101\n",
      "5800\n",
      "number of interesting articles: 2113\n",
      "6000\n",
      "number of interesting articles: 2128\n",
      "6200\n",
      "number of interesting articles: 2140\n",
      "6400\n",
      "number of interesting articles: 2144\n",
      "6600\n",
      "number of interesting articles: 2156\n",
      "6800\n",
      "number of interesting articles: 2168\n",
      "7000\n",
      "number of interesting articles: 2175\n",
      "7200\n",
      "number of interesting articles: 2187\n",
      "7400\n",
      "number of interesting articles: 2197\n",
      "7600\n",
      "number of interesting articles: 2206\n",
      "7800\n",
      "number of interesting articles: 2215\n",
      "8000\n",
      "number of interesting articles: 2221\n",
      "8200\n",
      "number of interesting articles: 2231\n",
      "8400\n",
      "number of interesting articles: 2241\n",
      "8600\n",
      "number of interesting articles: 2250\n",
      "8800\n",
      "number of interesting articles: 2260\n",
      "9000\n",
      "number of interesting articles: 2270\n",
      "9200\n",
      "number of interesting articles: 2282\n",
      "9400\n",
      "number of interesting articles: 2293\n",
      "9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of interesting articles: 2304\n",
      "9800\n",
      "number of interesting articles: 2322\n",
      "0\n",
      "number of interesting articles: 2330\n",
      "200\n",
      "number of interesting articles: 2335\n",
      "400\n",
      "number of interesting articles: 2344\n",
      "600\n",
      "number of interesting articles: 2349\n",
      "800\n",
      "number of interesting articles: 2352\n",
      "1000\n",
      "number of interesting articles: 2365\n",
      "1200\n",
      "number of interesting articles: 2376\n",
      "1400\n",
      "number of interesting articles: 2385\n",
      "1600\n",
      "number of interesting articles: 2397\n",
      "1800\n",
      "number of interesting articles: 2414\n",
      "2000\n",
      "number of interesting articles: 2428\n",
      "2200\n",
      "number of interesting articles: 2448\n",
      "2400\n",
      "number of interesting articles: 2463\n"
     ]
    }
   ],
   "source": [
    "to_date = '2024-06-22'    # 'YYYY-MM-DD'\n",
    "from_date = '2024-01-01'  # 'YYYY-MM-DD'\n",
    "\n",
    "arxiv_table_2024 = THE_FUNCTION(from_date, to_date)\n",
    "\n",
    "### To keep track of things we print overall number of \"interesting\" articles obtained based on the list of key words\n",
    "\n",
    "\n",
    "## 0\n",
    "## number of interesting articles: 4  \n",
    "## 200 <-- (number of  articles per page)\n",
    "## number of interesting articles: 5\n",
    "## 400 <--\n",
    "## number of interesting articles: 23\n",
    "## 600 <--\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cf912",
   "metadata": {},
   "source": [
    "###  Next couple of cells deal with different kinds of problems in cereral items\n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f46c71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For this article the was a glitch with article[0]\n",
    "\n",
    "for article in arxiv_table_2024:    \n",
    "    if article[1]== 'Geometrical methods in mathematical physics':\n",
    "       article[0] = \"https://arxiv.org/pdf/1311.0733.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "296bd856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Create additional columns 'mm.yyyy', 'yyyy', 'mm'  to newly created table\n",
    "\n",
    "\n",
    "for i in range(len(arxiv_table_2024)):\n",
    "    article_id = str(arxiv_table_2024[i][0])  # Convert to string to avoid TypeError\n",
    "    date = article_id[24:26] + '.20' + article_id[22:24]\n",
    "    year = '20' + article_id[-10:-8]\n",
    "    month = article_id[-8:-6]\n",
    "    arxiv_table_2024[i].append(date)\n",
    "    arxiv_table_2024[i].append(date[-4:])\n",
    "    arxiv_table_2024[i].append(date[:2])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7451b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your keyword categories\n",
    "categories = {\n",
    "    'Tensor_Networks': [\n",
    "        'tensor network', 'tensor networks', 'MERA', 'random tensor network', 'RTN', \n",
    "        'cMERA', 'hyperbolic lattices', 'continuous tensor network',\n",
    "        'tensor networks in machine learning', 'stabilizer state'\n",
    "    ],\n",
    "    'Holography': [\n",
    "        \"AdS/CFT\", \"BTZ black hole\", \"BTZ black holes\", \"RT formula\", \"bulk geometry\",\n",
    "        \"holographic code\", \"holographic duality\", \"quantum error-correcting code\",\n",
    "        \"holographic entanglement\", \"holographic shadow\", \"holography\", \"Renyi entropy\",\n",
    "        \"bit thread\", \"quantum bit threads\", \"emergent space-time geometry\",\n",
    "        \"geometry of entangled states\"\n",
    "    ],\n",
    "    'Black_Holes_and_GR': [\n",
    "        \"hawking radiation\", \"geodesics\", \"einstein equations\", \"traversable wormhole\",\n",
    "        \"traversable wormholes\", \"black holes\"\n",
    "    ],\n",
    "    'Quantum_Computers_and_Quantum_Information': [\n",
    "        \"entanglement of assistance\", \"entanglement of purification\", \"entanglement renormalization\",\n",
    "        \"quantum circuit\", \"quantum computer\", \"quantum error-correcting code\", \"quantum information theory\",\n",
    "        \"quantum machine learning\", \"tensor networks in machine learning\", \"random quantum circuits\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def categorize_articles(articles, categories):\n",
    "    for article in articles:\n",
    "        # Extract the keywords dictionary from the article\n",
    "        keywords_dict = article[4]\n",
    "        # Initialize a list to store categories for this article\n",
    "        article_categories = []\n",
    "        \n",
    "        # Iterate over each category and its associated keywords\n",
    "        for category_name, keywords_list in categories.items():\n",
    "            # Convert the category name into a properly spaced string\n",
    "            # only replacing the first occurrence of '_and_' with ' and '\n",
    "            formatted_category_name = category_name.replace('_', ' ').replace(' and ', ' and ', 1)\n",
    "            \n",
    "            # Check if any keyword from the current category is in the article's keyword dictionary\n",
    "            if any(keyword for keyword in keywords_list if keyword in keywords_dict):\n",
    "                # If any keyword matches, append the properly formatted category name to the article's categories\n",
    "                article_categories.append(formatted_category_name)\n",
    "        \n",
    "        # Replace or append the new categories list to the existing article\n",
    "        if len(article) > 8:  # If categories were already assigned, replace them\n",
    "            article[8] = article_categories\n",
    "        else:  # Otherwise, append the new categories list\n",
    "            article.append(article_categories)\n",
    "\n",
    "# Apply the updated function to your articles\n",
    "categorize_articles(arxiv_table_2024, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71c533e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_articles = []\n",
    "unique_urls = set()  # A set to track URLs of articles we've already added\n",
    "\n",
    "for article in arxiv_table_2024:\n",
    "    if article[0] not in unique_urls:  # Check if the article's URL is new\n",
    "        unique_articles.append(article)  # Add the article to the list of unique articles\n",
    "        unique_urls.add(article[0])  # Mark this URL as seen\n",
    "\n",
    "arxiv_table_2024 = unique_articles  # Replace the original list with the list of unique articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35a5f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For this article the was a glitch with article[3]\n",
    "\n",
    "for article in arxiv_table_2024:    \n",
    "    if article[1]== 'Detecting Measurement-Induced Entanglement Transitions With Unitary Mirror Circuits':\n",
    "       print(article) \n",
    "       article[3] = \"Monitored random circuits, consisting of alternating layers of entangling two-qubit gates and projective single-qubit measurements applied to some fraction $p$ of the qubits, have been a topic of recent interest. In particular, the resulting steady state exhibits a phase transition from highly correlated states with &#34;volume-law&#34; entanglement at $p&lt;p_{c}$ to localized states with &#34;area-law&#34; entanglement at $p&gt;p_{c}$. It is hard to access this transition experimentally, as it cannot be seen at the ensemble level. Naively, to observe it one must repeat the experiment until the set of measurement results repeats itself, with likelihood that is exponentially small in the number of measurements. To overcome this issue, we present a hybrid quantum-classical algorithm which creates a matrix product state (MPS) based &#34;unitary mirror&#34; of the projected circuit. Polynomial-sized tensor networks can represent quantum states with area-law entanglement, and so the unitary mirror can well-approximate the experimental state above $p_{c}$ but fails exponentially below it. The breaking of this mirror can thus pinpoint the critical point. We outline the algorithm and how such results would be obtained. We present a bound on the maximum entanglement entropy of any given state that is well-represented by an MPS, and from the bound suggest how the volume-law phase can be bounded. We consider whether the entanglement could similarly be bounded from below where the MPS fails. Finally, we present numerical results for small qubit numbers and for monitored circuits with random Clifford gates.\"\n",
    "       print('\\n',article) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cb97a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970\n",
      "Stored 'arxiv_table_2024' (list)\n"
     ]
    }
   ],
   "source": [
    "print(len(arxiv_table_2024))\n",
    "%store arxiv_table_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5956f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the list of lists to a pandas DataFrame\n",
    "df = pd.DataFrame(arxiv_table_2024, columns=['Link', 'Title', 'Authors', 'Abstract', 'Keywords', 'Date', 'Year', 'Month', 'Topic'])\n",
    "\n",
    "# Set the index to the titles\n",
    "df.set_index('Title', inplace=True)\n",
    "\n",
    "# Apply some formatting and styling\n",
    "styled_df = df.style \\\n",
    "    .set_properties(**{'text-align': 'left'}) \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('text-align', 'left')]\n",
    "    }, {\n",
    "        'selector': 'tr:nth-of-type(odd)',\n",
    "        'props': [('background-color', 'lightgray')]\n",
    "    }])\n",
    "\n",
    "%store df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73ef6db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bb9e3 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bb9e3 tr:nth-of-type(odd) {\n",
       "  background-color: lightgray;\n",
       "}\n",
       "#T_bb9e3_row0_col0, #T_bb9e3_row0_col1, #T_bb9e3_row0_col2, #T_bb9e3_row0_col3, #T_bb9e3_row0_col4, #T_bb9e3_row0_col5, #T_bb9e3_row0_col6, #T_bb9e3_row0_col7, #T_bb9e3_row1_col0, #T_bb9e3_row1_col1, #T_bb9e3_row1_col2, #T_bb9e3_row1_col3, #T_bb9e3_row1_col4, #T_bb9e3_row1_col5, #T_bb9e3_row1_col6, #T_bb9e3_row1_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bb9e3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bb9e3_level0_col0\" class=\"col_heading level0 col0\" >Link</th>\n",
       "      <th id=\"T_bb9e3_level0_col1\" class=\"col_heading level0 col1\" >Authors</th>\n",
       "      <th id=\"T_bb9e3_level0_col2\" class=\"col_heading level0 col2\" >Abstract</th>\n",
       "      <th id=\"T_bb9e3_level0_col3\" class=\"col_heading level0 col3\" >Keywords</th>\n",
       "      <th id=\"T_bb9e3_level0_col4\" class=\"col_heading level0 col4\" >Date</th>\n",
       "      <th id=\"T_bb9e3_level0_col5\" class=\"col_heading level0 col5\" >Year</th>\n",
       "      <th id=\"T_bb9e3_level0_col6\" class=\"col_heading level0 col6\" >Month</th>\n",
       "      <th id=\"T_bb9e3_level0_col7\" class=\"col_heading level0 col7\" >Topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Title</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bb9e3_level0_row0\" class=\"row_heading level0 row0\" >Parameterized quasinormal frequencies and Hawking radiation for axial gravitational perturbations of a holonomy-corrected black hole</th>\n",
       "      <td id=\"T_bb9e3_row0_col0\" class=\"data row0 col0\" >https://arxiv.org/pdf/2406.15711v1</td>\n",
       "      <td id=\"T_bb9e3_row0_col1\" class=\"data row0 col1\" >Sen Yang, Wen-Di Guo, Qin Tan, Li Zhao, Yu-Xiao Liu</td>\n",
       "      <td id=\"T_bb9e3_row0_col2\" class=\"data row0 col2\" >As the fingerprints of black holes, quasinormal modes are closely associated with many properties of black holes. Especially, the ringdown phase of gravitational waveforms from the merger of compact binary components can be described by quasinormal modes. Serving as a model-independent approach, the framework of parameterized quasinormal frequencies offers a universal method for investigating quasinormal modes of diverse black holes. In this work, we first obtain the Schrödinger-like master equation of the axial gravitational perturbation of a holonomy-corrected black hole. We calculate the corresponding quasinormal frequencies using the Wentzel-Kramers-Brillouin approximation and asymptotic iteration methods. We investigate the numerical evolution of an initial wave packet on the background spacetime. Then, we deduce the parameterized expression of the quasinormal frequencies and find that $r_0 \\leq 10^{-2}$ is a necessary condition for the parameterized approximation to be valid. We also study the impact of the quantum parameter $r_0$ on the greybody factor and Hawking radiation. With more ringdown signals of gravitational waves detected in the future, our research will contribute to the study of the quantum properties of black holes.</td>\n",
       "      <td id=\"T_bb9e3_row0_col3\" class=\"data row0 col3\" >{'black holes': 4, 'hawking radiation': 1}</td>\n",
       "      <td id=\"T_bb9e3_row0_col4\" class=\"data row0 col4\" >06.2024</td>\n",
       "      <td id=\"T_bb9e3_row0_col5\" class=\"data row0 col5\" >2024</td>\n",
       "      <td id=\"T_bb9e3_row0_col6\" class=\"data row0 col6\" >06</td>\n",
       "      <td id=\"T_bb9e3_row0_col7\" class=\"data row0 col7\" >['Black Holes and GR']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb9e3_level0_row1\" class=\"row_heading level0 row1\" >Observation of a non-Hermitian supersonic mode</th>\n",
       "      <td id=\"T_bb9e3_row1_col0\" class=\"data row1 col0\" >https://arxiv.org/pdf/2406.15557v1</td>\n",
       "      <td id=\"T_bb9e3_row1_col1\" class=\"data row1 col1\" >Yuxuan Zhang, Juan Carrasquilla, Yong Baek Kim</td>\n",
       "      <td id=\"T_bb9e3_row1_col2\" class=\"data row1 col2\" >Quantum computers have long been anticipated to excel in simulating quantum many-body physics. While most previous work has focused on Hermitian physics, we demonstrate the power of variational quantum circuits for resource-efficient simulations of dynamical and equilibrium physics in non-Hermitian systems, revealing new phenomena beyond standard Hermitian quantum machines. Using a variational quantum compilation scheme for fermionic systems, we reduce gate count, save qubits, and eliminate the need for postselection, a major challenge in simulating non-Hermitian dynamics via standard Trotterization. Experimentally, we observed a supersonic mode in the connected density-density correlation function on an $ n = 18 $ fermionic chain after a non-Hermitian, locally interacting quench, which would otherwise be forbidden by the Lieb-Robinson bound in a Hermitian system. Additionally, we investigate sequential quantum circuits generated by tensor networks for ground state preparation, here defined as the eigenstate with the lowest real part eigenvalue, using a variance minimization scheme. Through a trapped-ion implementation on the Quantinuum H1 quantum processor, we accurately capture correlation functions and energies across an exceptional point on a dissipative spin chain up to length $ n = 20 $ using only 3 qubits. Motivated by these advancements, we provide an analytical example demonstrating that simulating single-qubit non-Hermitian dynamics for $Θ(\\log(n))$ time from certain initial states is exponentially hard on a quantum computer, offering insights into the opportunities and limitations of using quantum computation for simulating non-Hermitian physics.</td>\n",
       "      <td id=\"T_bb9e3_row1_col3\" class=\"data row1 col3\" >{'quantum computer': 1, 'tensor networks': 1}</td>\n",
       "      <td id=\"T_bb9e3_row1_col4\" class=\"data row1 col4\" >06.2024</td>\n",
       "      <td id=\"T_bb9e3_row1_col5\" class=\"data row1 col5\" >2024</td>\n",
       "      <td id=\"T_bb9e3_row1_col6\" class=\"data row1 col6\" >06</td>\n",
       "      <td id=\"T_bb9e3_row1_col7\" class=\"data row1 col7\" >['Tensor Networks', 'Quantum Computers and Quantum Information']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f94f3b8b8b0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## If we show this way thw whole table (987 items) the notebook slows down\n",
    "\n",
    "df_slice = pd.DataFrame(arxiv_table_2024[:2], columns=['Link', 'Title', 'Authors', 'Abstract', 'Keywords', 'Date', 'Year', 'Month', 'Topic'])\n",
    "\n",
    "# Set the index to the titles\n",
    "df_slice.set_index('Title', inplace=True)\n",
    "\n",
    "# Apply some formatting and styling\n",
    "styled_df_slice = df_slice.style \\\n",
    "    .set_properties(**{'text-align': 'left'}) \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('text-align', 'left')]\n",
    "    }, {\n",
    "        'selector': 'tr:nth-of-type(odd)',\n",
    "        'props': [('background-color', 'lightgray')]\n",
    "    }])\n",
    "\n",
    "styled_df_slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b753b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df.to_csv('table_arxiv_24-01-01__2024-06-22.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a880184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c4b42",
   "metadata": {},
   "source": [
    " # This is essentially the end of the project.  \n",
    " ## The rest of the notebook splits this overall table into several smaller ones based on Topics.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9b52d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN_table_2024 = []  # List to hold articles related to Tensor Networks\n",
    "\n",
    "for article in arxiv_table_2024:\n",
    "    # Check if 'Tensor Networks' is in the list of topics (which is the last element of the article)\n",
    "    if 'Tensor Networks' in article[-1]:\n",
    "        TN_table_2024.append(article)  # Add the whole article to the TN_table_2024 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "110eb098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "Stored 'TN_table_2024' (list)\n"
     ]
    }
   ],
   "source": [
    "print(len(TN_table_2024))\n",
    "%store TN_table_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2260c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Holography_table_2024 = []  # List to hold articles related to Holography\n",
    "\n",
    "for article in arxiv_table_2024:\n",
    "    # Check if 'Holography' is in the list of topics (which is the last element of the article)\n",
    "    if 'Holography' in article[-1]:\n",
    "        Holography_table_2024.append(article)  # Add the whole article to the Holography_table_2024 list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8305ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n"
     ]
    }
   ],
   "source": [
    "print(len(Holography_table_2024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e551b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d0d32 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d0d32 tr:nth-of-type(odd) {\n",
       "  background-color: lightgray;\n",
       "}\n",
       "#T_d0d32_row0_col0, #T_d0d32_row0_col1, #T_d0d32_row0_col2, #T_d0d32_row0_col3, #T_d0d32_row0_col4, #T_d0d32_row0_col5, #T_d0d32_row0_col6, #T_d0d32_row0_col7, #T_d0d32_row1_col0, #T_d0d32_row1_col1, #T_d0d32_row1_col2, #T_d0d32_row1_col3, #T_d0d32_row1_col4, #T_d0d32_row1_col5, #T_d0d32_row1_col6, #T_d0d32_row1_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d0d32\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d0d32_level0_col0\" class=\"col_heading level0 col0\" >Link</th>\n",
       "      <th id=\"T_d0d32_level0_col1\" class=\"col_heading level0 col1\" >Authors</th>\n",
       "      <th id=\"T_d0d32_level0_col2\" class=\"col_heading level0 col2\" >Abstract</th>\n",
       "      <th id=\"T_d0d32_level0_col3\" class=\"col_heading level0 col3\" >Keywords</th>\n",
       "      <th id=\"T_d0d32_level0_col4\" class=\"col_heading level0 col4\" >Date</th>\n",
       "      <th id=\"T_d0d32_level0_col5\" class=\"col_heading level0 col5\" >Year</th>\n",
       "      <th id=\"T_d0d32_level0_col6\" class=\"col_heading level0 col6\" >Month</th>\n",
       "      <th id=\"T_d0d32_level0_col7\" class=\"col_heading level0 col7\" >Topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Title</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d0d32_level0_row0\" class=\"row_heading level0 row0\" >Observation of a non-Hermitian supersonic mode</th>\n",
       "      <td id=\"T_d0d32_row0_col0\" class=\"data row0 col0\" >https://arxiv.org/pdf/2406.15557v1</td>\n",
       "      <td id=\"T_d0d32_row0_col1\" class=\"data row0 col1\" >Yuxuan Zhang, Juan Carrasquilla, Yong Baek Kim</td>\n",
       "      <td id=\"T_d0d32_row0_col2\" class=\"data row0 col2\" >Quantum computers have long been anticipated to excel in simulating quantum many-body physics. While most previous work has focused on Hermitian physics, we demonstrate the power of variational quantum circuits for resource-efficient simulations of dynamical and equilibrium physics in non-Hermitian systems, revealing new phenomena beyond standard Hermitian quantum machines. Using a variational quantum compilation scheme for fermionic systems, we reduce gate count, save qubits, and eliminate the need for postselection, a major challenge in simulating non-Hermitian dynamics via standard Trotterization. Experimentally, we observed a supersonic mode in the connected density-density correlation function on an $ n = 18 $ fermionic chain after a non-Hermitian, locally interacting quench, which would otherwise be forbidden by the Lieb-Robinson bound in a Hermitian system. Additionally, we investigate sequential quantum circuits generated by tensor networks for ground state preparation, here defined as the eigenstate with the lowest real part eigenvalue, using a variance minimization scheme. Through a trapped-ion implementation on the Quantinuum H1 quantum processor, we accurately capture correlation functions and energies across an exceptional point on a dissipative spin chain up to length $ n = 20 $ using only 3 qubits. Motivated by these advancements, we provide an analytical example demonstrating that simulating single-qubit non-Hermitian dynamics for $Θ(\\log(n))$ time from certain initial states is exponentially hard on a quantum computer, offering insights into the opportunities and limitations of using quantum computation for simulating non-Hermitian physics.</td>\n",
       "      <td id=\"T_d0d32_row0_col3\" class=\"data row0 col3\" >{'quantum computer': 1, 'tensor networks': 1}</td>\n",
       "      <td id=\"T_d0d32_row0_col4\" class=\"data row0 col4\" >06.2024</td>\n",
       "      <td id=\"T_d0d32_row0_col5\" class=\"data row0 col5\" >2024</td>\n",
       "      <td id=\"T_d0d32_row0_col6\" class=\"data row0 col6\" >06</td>\n",
       "      <td id=\"T_d0d32_row0_col7\" class=\"data row0 col7\" >['Tensor Networks', 'Quantum Computers and Quantum Information']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d0d32_level0_row1\" class=\"row_heading level0 row1\" >Tensor Decompositions and Adiabatic Quantum Computing for Discovering Practical Matrix Multiplication Algorithms</th>\n",
       "      <td id=\"T_d0d32_row1_col0\" class=\"data row1 col0\" >https://arxiv.org/pdf/2406.13412v1</td>\n",
       "      <td id=\"T_d0d32_row1_col1\" class=\"data row1 col1\" >Valter Uotila</td>\n",
       "      <td id=\"T_d0d32_row1_col2\" class=\"data row1 col2\" >Quantum computing and modern tensor-based computing have a strong connection, which is especially demonstrated by simulating quantum computations with tensor networks. The other direction is less studied: quantum computing is not often applied to tensor-based problems. Considering tensor decompositions, we focus on discovering practical matrix multiplication algorithms and develop two algorithms to compute decompositions on quantum computers. The algorithms are expressed as higher-order unconstrained binary optimization (HUBO) problems, which are translated into quadratic unconstrained binary optimization (QUBO) problems. Our first algorithm is decompositional to keep the optimization problem feasible for the current quantum devices. Starting from a suitable initial point, the algorithm discovers tensor decomposition corresponding to the famous Strassen matrix multiplication algorithm, utilizing the current quantum annealers. Since the decompositional algorithm does not guarantee minimal length for found tensor decompositions, we develop a holistic algorithm that can find fixed-length decompositions. Theoretically, by fixing a shorter length than the length for the best-known decomposition, we can ensure that the solution to the holistic optimization problem would yield faster matrix multiplication algorithms.</td>\n",
       "      <td id=\"T_d0d32_row1_col3\" class=\"data row1 col3\" >{'tensor networks': 1}</td>\n",
       "      <td id=\"T_d0d32_row1_col4\" class=\"data row1 col4\" >06.2024</td>\n",
       "      <td id=\"T_d0d32_row1_col5\" class=\"data row1 col5\" >2024</td>\n",
       "      <td id=\"T_d0d32_row1_col6\" class=\"data row1 col6\" >06</td>\n",
       "      <td id=\"T_d0d32_row1_col7\" class=\"data row1 col7\" >['Tensor Networks']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f94f464caf0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of lists to a pandas DataFrame\n",
    "df_TN = pd.DataFrame(TN_table_2024[:2], columns=['Link', 'Title', 'Authors', 'Abstract', 'Keywords', 'Date', 'Year', 'Month', 'Topic'])\n",
    "\n",
    "# Set the index to the titles\n",
    "df_TN.set_index('Title', inplace=True)\n",
    "\n",
    "# Apply some formatting and styling\n",
    "styled_df_TN = df_TN.style \\\n",
    "    .set_properties(**{'text-align': 'left'}) \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('text-align', 'left')]\n",
    "    }, {\n",
    "        'selector': 'tr:nth-of-type(odd)',\n",
    "        'props': [('background-color', 'lightgray')]\n",
    "    }])\n",
    "\n",
    "#%store df\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df_TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d17742dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_654ca th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_654ca tr:nth-of-type(odd) {\n",
       "  background-color: lightgray;\n",
       "}\n",
       "#T_654ca_row0_col0, #T_654ca_row0_col1, #T_654ca_row0_col2, #T_654ca_row0_col3, #T_654ca_row0_col4, #T_654ca_row0_col5, #T_654ca_row0_col6, #T_654ca_row0_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_654ca\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_654ca_level0_col0\" class=\"col_heading level0 col0\" >Link</th>\n",
       "      <th id=\"T_654ca_level0_col1\" class=\"col_heading level0 col1\" >Authors</th>\n",
       "      <th id=\"T_654ca_level0_col2\" class=\"col_heading level0 col2\" >Abstract</th>\n",
       "      <th id=\"T_654ca_level0_col3\" class=\"col_heading level0 col3\" >Keywords</th>\n",
       "      <th id=\"T_654ca_level0_col4\" class=\"col_heading level0 col4\" >Date</th>\n",
       "      <th id=\"T_654ca_level0_col5\" class=\"col_heading level0 col5\" >Year</th>\n",
       "      <th id=\"T_654ca_level0_col6\" class=\"col_heading level0 col6\" >Month</th>\n",
       "      <th id=\"T_654ca_level0_col7\" class=\"col_heading level0 col7\" >Topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Title</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_654ca_level0_row0\" class=\"row_heading level0 row0\" >Phase space framework enables a variable-scale diffraction model for coherent imaging and display</th>\n",
       "      <td id=\"T_654ca_row0_col0\" class=\"data row0 col0\" >https://arxiv.org/pdf/2406.15456v1</td>\n",
       "      <td id=\"T_654ca_row0_col1\" class=\"data row0 col1\" >Zhi Li, Xuhao Luo, Jing Wang, Xin Yuan, Dongdong Teng, Qiang Song, Huigao Duan</td>\n",
       "      <td id=\"T_654ca_row0_col2\" class=\"data row0 col2\" >The fast algorithms in Fourier optics have invigorated multifunctional device design and advanced imaging technologies. However, the necessity for fast computations has led to limitations in the widely used conventional Fourier methods, manifesting as fixed size image plane at a certain diffraction distance. These limitations pose challenges in intricate scaling transformations, 3D reconstructions and full-color displays. Currently, there is a lack of effective solutions, often resorting to pre-processing that compromise fidelity. In this paper, leveraging a higher-dimensional phase space method, we present a universal framework allowing for customized diffraction calculation methods. Within this framework, we establish a variable-scale diffraction computation model which allows the adjustment of the size of the image plane and can be operated by fast algorithms. We validate the model's robust variable-scale capabilities and its aberration automatic correction capability for full-color holography, achieving high fidelity. The large-magnification tomography experiment demonstrates that this model provides a superior solution for holographic 3D reconstruction. In addition, this model is applied to achieve full-color metasurface holography with near-zero crosstalk, showcasing its versatile applicability at nanoscale. Our model presents significant prospects for applications in the optics community, such as beam shaping, computer-generated holograms (CGHs), augmented reality (AR), metasurface optical elements (MOEs) and advanced holographic head-up display (HUD) systems.</td>\n",
       "      <td id=\"T_654ca_row0_col3\" class=\"data row0 col3\" >{'holography': 2}</td>\n",
       "      <td id=\"T_654ca_row0_col4\" class=\"data row0 col4\" >06.2024</td>\n",
       "      <td id=\"T_654ca_row0_col5\" class=\"data row0 col5\" >2024</td>\n",
       "      <td id=\"T_654ca_row0_col6\" class=\"data row0 col6\" >06</td>\n",
       "      <td id=\"T_654ca_row0_col7\" class=\"data row0 col7\" >['Holography']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f94f630afa0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of lists to a pandas DataFrame\n",
    "df_Holography = pd.DataFrame(Holography_table_2024[:1], columns=['Link', 'Title', 'Authors', 'Abstract', 'Keywords', 'Date', 'Year', 'Month', 'Topic'])\n",
    "\n",
    "# Set the index to the titles\n",
    "df_Holography.set_index('Title', inplace=True)\n",
    "\n",
    "# Apply some formatting and styling\n",
    "styled_df_Holography = df_Holography.style \\\n",
    "    .set_properties(**{'text-align': 'left'}) \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('text-align', 'left')]\n",
    "    }, {\n",
    "        'selector': 'tr:nth-of-type(odd)',\n",
    "        'props': [('background-color', 'lightgray')]\n",
    "    }])\n",
    "\n",
    "#%store df\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df_Holography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f08e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
